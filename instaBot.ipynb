{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instagrame Scraper Bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation\n",
    "In this code, we embark on an exploration of web scraping techniques using Selenium to gather profile's information from Instagram of different tags. Perfomed the folwoing steps.\n",
    "\n",
    "1. Setting Up Selenium WebDriver  \n",
    "Set up the Selenium WebDriver for Chrome. The chromedriverPath variable points to the location of the ChromeDriver executable, facilitating seamless interaction between our script and the Chrome browser.\n",
    "\n",
    "\n",
    "2. Logging into Instagram  \n",
    "Automation begins with logging into Instagram. Selenium facilitates the interaction with the login page, automating the process of entering credentials and submitting the form. Timed waits ensure synchronization with the dynamic nature of web pages, allowing the script to adapt to varying load times. \n",
    "3. Searching for Hashtags and Scraping Data  \n",
    "The script iterates through a predefined list of hashtags, initiating a sequence of actions to locate, click, and extract relevant information from each post. The use of try-except blocks enhances the script's robustness, enabling it to gracefully handle exceptions and continue the scraping process.\n",
    "4. Writing Data to CSV   \n",
    "The writeListToCsv function takes care of this task, creating a CSV file named 'output0.csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports here\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "import time\n",
    "import csv\n",
    "\n",
    "chromedriverPath = r'C:\\Users\\driver\\chromedriver.exe'\n",
    "# Create a Service object with the path to chromedriver\n",
    "chromeService = webdriver.chrome.service.Service(chromedriverPath)\n",
    "# Start the service\n",
    "chromeService.start()\n",
    "# Create the WebDriver using the Service object\n",
    "driver = webdriver.Chrome(service=chromeService)\n",
    "\n",
    "# Open the webpage\n",
    "driver.get(\"http://www.instagram.com\")\n",
    "\n",
    "wait = WebDriverWait(driver, 10)\n",
    "# Target username\n",
    "username = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='username']\")))\n",
    "password = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='password']\")))\n",
    "\n",
    "# Enter username and password\n",
    "username.clear()\n",
    "username.send_keys(\"sherysha122\")\n",
    "password.clear()\n",
    "password.send_keys(\"Sha4566781\")\n",
    "\n",
    "time.sleep(3)\n",
    "# Target the login button and click it\n",
    "button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button[type='submit']\"))).click()\n",
    "time.sleep(5)\n",
    "# alert1 = wait.until(EC.element_to_be_clickable((By.XPATH, '//button[contains(text(), \"Not now\")]'))).click()\n",
    "alert = wait.until(EC.element_to_be_clickable((By.CLASS_NAME, '_ac8f'))).click()\n",
    "time.sleep(3)\n",
    "alert2 = wait.until(EC.element_to_be_clickable((By.XPATH, '//button[contains(text(), \"Not Now\")]'))).click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "keywords = ['#hairdresser', '#doggroomer']\n",
    "data7 = []\n",
    "\n",
    "# Loop through the keywords\n",
    "for keyword in keywords:\n",
    "    try:\n",
    "        # Target the search input field\n",
    "        second_child_div = wait.until(EC.element_to_be_clickable((By.XPATH, '//*[@class=\"x1iyjqo2 xh8yej3\"]/div[2]')))\n",
    "        second_child_div.click()\n",
    "        searchbox = wait.until(EC.element_to_be_clickable((By.XPATH, \"//input[@placeholder='Search']\")))\n",
    "        searchbox.clear()\n",
    "        # Search for the hashtag cat\n",
    "        searchbox.send_keys(keyword)\n",
    "        # Fixing the double enter\n",
    "        myLink = wait.until(EC.element_to_be_clickable((By.XPATH, \"//a[contains(@href, '/\" + keyword[1:] + \"/')]\")))\n",
    "        myLink.click()\n",
    "        time.sleep(4)\n",
    "\n",
    "        # Scroll down the page up to 3 times to load more posts\n",
    "        # scrollCount = 0\n",
    "        # while scrollCount < 3:\n",
    "        #     driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "        #     time.sleep(2)  # Wait for the page to load\n",
    "        #     scrollCount += 1\n",
    "\n",
    "        # Get the links of all the posts\n",
    "        postLinks = driver.find_elements(By.CSS_SELECTOR, 'a[href^=\"/p/\"]')\n",
    "        postLinks = [link.get_attribute('href') for link in postLinks]\n",
    "        del postLinks[3:]  # This will delete the elements\n",
    "\n",
    "        # Initialize the wait variable\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "\n",
    "        # Loop through each post link and scrape the profile information\n",
    "        for postLink in postLinks:\n",
    "            try:\n",
    "                # Navigate to the post page\n",
    "                driver.get(postLink)\n",
    "                time.sleep(4)  # Wait for the post to load\n",
    "\n",
    "                # Click on the post to open the popup post\n",
    "                post = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"span.xt0psk2\")))\n",
    "                post.click()\n",
    "                time.sleep(4)  # Wait for the popup post to load\n",
    "\n",
    "                try:\n",
    "                    time.sleep(4)\n",
    "                    profileName = driver.find_element(By.CSS_SELECTOR, 'h2').text\n",
    "                except:\n",
    "                    profileName = 'none'\n",
    "\n",
    "                try:\n",
    "                    # Find the element that contains the followers count\n",
    "                    followerCount = driver.find_element(By.XPATH, \"//a[contains(@href, '/followers')]\").text\n",
    "                except:\n",
    "                    followerCount = 'none'\n",
    "\n",
    "                try:\n",
    "                    bio = driver.find_element(By.CSS_SELECTOR, 'div.x7a106z h1').text\n",
    "                except:\n",
    "                    bio = 'none'\n",
    "\n",
    "                data7.append((postLink, profileName, followerCount, bio))\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error scraping profile: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        # Go back to the search results page\n",
    "        driver.get('https://www.instagram.com')\n",
    "        time.sleep(2)  # Wait for the page to load\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error searching for keyword: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "def writeListToCsv(dataList, csvFile):\n",
    "\n",
    "    with open(csvFile, 'w', newline='', encoding='utf-8') as file:\n",
    "        csvWriter = csv.writer(file)\n",
    "\n",
    "        # Write each item to the CSV file\n",
    "        for item in dataList:\n",
    "            csvWriter.writerow([item])\n",
    "\n",
    "writeListToCsv(data7, 'output0.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import csv\n",
    "import time\n",
    "\n",
    "def loginInstagram(username, password, driver):\n",
    "    driver.get(\"http://www.instagram.com\")\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "\n",
    "    usernameElem = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='username']\")))\n",
    "    passwordElem = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='password']\")))\n",
    "    usernameElem.clear()\n",
    "    usernameElem.send_keys(username)\n",
    "    passwordElem.clear()\n",
    "    passwordElem.send_keys(password)\n",
    "    wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button[type='submit']\"))).click()\n",
    "    wait.until(EC.element_to_be_clickable((By.CLASS_NAME, '_ac8f'))).click()\n",
    "    wait.until(EC.element_to_be_clickable((By.XPATH, '//button[contains(text(), \"Not Now\")]'))).click()\n",
    "\n",
    "def searchAndScrape(keyword, driver, wait, dataList):\n",
    "    try:\n",
    "        wait.until(EC.element_to_be_clickable((By.XPATH, '//*[@class=\"x1iyjqo2 xh8yej3\"]/div[2]'))).click()\n",
    "        searchbox = wait.until(EC.element_to_be_clickable((By.XPATH, \"//input[@placeholder='Search']\")))\n",
    "        searchbox.clear()\n",
    "        searchbox.send_keys(keyword)\n",
    "        myLink = wait.until(EC.element_to_be_clickable((By.XPATH, f\"//a[contains(@href, '/{keyword[1:]}/')]\")))\n",
    "        myLink.click()\n",
    "        time.sleep(4)\n",
    "\n",
    "        postLinks = driver.find_elements(By.CSS_SELECTOR, 'a[href^=\"/p/\"]')\n",
    "        del postLinks[3:] # keep the links upto index 3 and delete onward links\n",
    "        postLinks = [link.get_attribute('href') for link in postLinks]\n",
    "\n",
    "        for postLink in postLinks:\n",
    "            try:\n",
    "                driver.get(postLink)\n",
    "                time.sleep(4)\n",
    "                post = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"span.xt0psk2\")))\n",
    "                post.click()\n",
    "                time.sleep(4)\n",
    "\n",
    "                try:\n",
    "                    time.sleep(4)\n",
    "                    profileName = driver.find_element(By.CSS_SELECTOR, 'h2').text\n",
    "                except NoSuchElementException:\n",
    "                    profileName = 'none'\n",
    "\n",
    "                try:\n",
    "                    followerCount = driver.find_element(By.XPATH, \"//a[contains(@href, '/followers')]\").text\n",
    "                except NoSuchElementException:\n",
    "                    followerCount = 'none'\n",
    "\n",
    "                try:\n",
    "                    bio = driver.find_element(By.CSS_SELECTOR, 'div.x7a106z h1').text\n",
    "                except NoSuchElementException:\n",
    "                    bio = 'none'\n",
    "\n",
    "                dataList.append({\n",
    "                    \"postLink\": postLink,\n",
    "                    \"profileName\": profileName,\n",
    "                    \"followerCount\": followerCount,\n",
    "                    \"bio\": bio\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error scraping profile: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        driver.get('https://www.instagram.com')\n",
    "        time.sleep(2)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error searching for keyword: {str(e)}\")\n",
    "        return\n",
    "\n",
    "def writeListToCsv(dataList, csvFile):\n",
    "    with open(csvFile, 'w', newline='', encoding='utf-8') as file:\n",
    "        csvWriter = csv.DictWriter(file, fieldnames=[\"postLink\", \"profileName\", \"followerCount\", \"bio\"])\n",
    "        csvWriter.writeheader()\n",
    "        csvWriter.writerows(dataList)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "chromeDriverPath = r'C:\\Users\\driver\\chromedriver.exe'\n",
    "driver = webdriver.Chrome(service=webdriver.chrome.service.Service(chromeDriverPath))\n",
    "\n",
    "# Login\n",
    "loginInstagram(\"sherysha122\", \"Sha4566781\", driver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ddataList' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     searchAndScrape(keyword, driver, wait, dataList)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Write data to CSV\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m writeListToCsv(\u001b[43mddataList\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput0.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# # Close the browser\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# driver.quit()\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ddataList' is not defined"
     ]
    }
   ],
   "source": [
    "# Data scraping and collection\n",
    "dataList = []\n",
    "wait = WebDriverWait(driver, 10)\n",
    "keywords = ['#hairdresser', '#doggroomer']\n",
    "\n",
    "for keyword in keywords:\n",
    "    searchAndScrape(keyword, driver, wait, dataList)\n",
    "\n",
    "# Write data to CSV\n",
    "writeListToCsv(dataList, 'output0.csv')\n",
    "\n",
    "# # Close the browser\n",
    "# driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
